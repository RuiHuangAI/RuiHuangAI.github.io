---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

#  About Me

Hello! ğŸ‘ Iâ€™m a third-year undergraduate student in **[UESTCâ€™s â€œEverest Projectâ€](https://www.uestc.edu.cn/%22%E5%AD%A6%E6%A0%A1%E5%AE%98%E7%BD%91%E2%80%9C)** Computer Top-Talent Experimental Class (2023â€“2027), majoring in Computer Science. Now, Iâ€™m interested in **LLM SFT/RL and reasoning, image/video generation, and unified multimodal models**. Earlier, I explored AI for smart grids and remote-sensing image fusion. You can find my [resume](https://ruihuangai.github.io/files/cv/RuiHuang_CV%202025.10.pdf) or [ä¸­æ–‡ç®€å†](https://ruihuangai.github.io/files/cv/RuiHuang_CV%20(Chinese)2025.10.pdf) here.

â­  I am eager to discuss potential collaborations and am **actively seeking research internship opportunities(industry/academia),including onsite roles**.I â€˜m also seeking for **2027 fall PHD position**. Please feel free to contact me via **email**: [huang_rui@std.uestc.edu.cn],[paulafixamiworali@gmail.com] or **WeChat: huangrui_dby** if you are interested.I warmly welcome your message and look forward to connecting!

# ğŸ”¥ News


- *2024.10*: &nbsp;ğŸ† I am happy to be awarded the **National Scholarship** of 2025.


- *2025.09*: &nbsp;ğŸ‰ We pre-released [**UniVA**](https://univa-agent.github.io/), first to unify Video **Understanding/Segmentation/Editing/Generation** into traceable multi-step workflows via Planâ€“Act agents, multi-level memory, and modular tools, plus UniVA-Bench!


- *2025.07*: &nbsp;ğŸ‰ I'm honored to be invited to be a reviewer of **AAAI 2026**!


- *2025.06*: &nbsp;ğŸ† I'm so happy to be 1/30 of **SenseTime Scholarship 2025!** *This is the greatest praise I have received so far.* 

- *2025.06*: &nbsp;ğŸ‰ We pre-released [**Diffusion Dataset Condensation**](https://arxiv.org/abs/2507.05914) on arXiv, **accelerating the pre-training of diffusion models by 100x**!!!. The entire project used **hundreds of H100/A100**!!

- *2025.06*: &nbsp;ğŸ‰ One paper has been accepted by [**IEEE Transactions on Industrial Informatics**](https://ieeexplore.ieee.org/abstract/document/11036164), completed during my first research internship in AI for smart grid.


- *2025.03*: &nbsp;ğŸ‰ We released [**CoT Image**](https://arxiv.org/abs/2501.13926), The first to **introduce CoT-style strategies into image generation**, it has attracted widespread attention in the community and received over **790+ stars**!!


- *2024.12*: &nbsp;ğŸ‰ Our paper [**Wavelet-Assisted Multi-Frequency Attention Network for Pansharpening**](https://ojs.aaai.org/index.php/AAAI/article/view/32381) has been accepted by **AAAI 2025** and selected for **Oral Presentation**. See you in Philadelphia!!!!



- *2024.10*: &nbsp;ğŸ† I am happy to be awarded the **National Scholarship** of 2024 and the **Gratitude Scholarship for Modern Scientists**.



- *2024.09*: &nbsp;ğŸ‰ One paper has been accepted by [**IEEE Transactions on Sustainable Energy**](https://ieeexplore.ieee.org/abstract/document/10679087/), completed during my first research internship in AI for smart grid.

- *2024.08*: &nbsp;ğŸ‰ I am delighted to be going to **Cambridge as a visiting student**.

- *2023.12*: &nbsp;ğŸŒ± The starting point of my academic journey.






# ğŸ“ Selected Publications ï¼† Preprints


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Under Review</div><img src='images/D2C.png' alt="D2C" style="width: 100%; height: auto; object-fit: cover; max-height: 200px;"></div></div>
<div class='paper-box-text' markdown="1">

[ğŸ”¥Diffusion Dataset Condensation: Training Your Diffusion Model Faster with Less Data](https://arxiv.org/abs/2507.05914)

**Rui Huang**<sup style="font-size: 1.1em; position: relative; top: -2px;">*</sup> , Shitong Shao<sup style="font-size: 1.1em; position: relative; top: -2px;">*</sup> , Zikai Zhou, Pukun Zhao, Hangyu Guo, Tian Ye, Lichen Bai, Shuo Yang, Zeke Xie<sup>â€ </sup>



[**[PDF]**](https://arxiv.org/abs/2507.05914) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> **[Github]**    <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

**TL;DR:** *Proposed DÂ²C: Diffusion Dataset Condensation for diffusion models, **enabling 100Ã— faster training** with 0.8%â€“4% data via sample selection and semantic enhancement; **trained on hundreds of A800/H100 GPUs.***

</div>
</div>








<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2025 Oral</div><img src='images/WFANet.png' alt="D2C" style="width: 100%; height: auto; object-fit: cover; max-height: 200px;"></div></div>
<div class='paper-box-text' markdown="1">

[ğŸ”¥Wavelet-Assisted Multi-Frequency Attention Network for Pansharpening](https://arxiv.org/pdf/2502.04903)

Jie Huang<sup style="font-size: 1.1em; position: relative; top: -2px;">*</sup>, **Rui Huang**<sup style="font-size: 1.1em; position: relative; top: -2px;">*</sup>, Jinghao Xu, Siran Pen, Yule Duan, Liangjian Deng<sup>â€ </sup>



[**[PDF]**](https://arxiv.org/pdf/2502.04903) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>    [**[Github]**](https://github.com/Jie-1203/WFANet) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

**TL;DR:** *Proposed WFANet for image fusion, **combining wavelet transformation with attention**, achieving SOTA on multiple datasets.*

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Under Review</div><img src='images/CoTImage.png' alt="D2C" style="width: 100%; height: auto; object-fit: cover; max-height: 200px;"></div></div>
<div class='paper-box-text' markdown="1">

[ğŸ”¥Can We Generate Images with CoT? Let's Verify and Reinforce Image Generation Step by Step](https://arxiv.org/pdf/2501.13926)

Ziyu Guo<sup style="font-size: 1.1em; position: relative; top: -2px;">*</sup>, Renrui Zhang<sup style="font-size: 1.1em; position: relative; top: -2px;">*</sup><sup>â€ </sup>, Chengzhuo Tong<sup style="font-size: 1.1em; position: relative; top: -2px;">*</sup>, Zhizheng Zhao<sup style="font-size: 1.1em; position: relative; top: -2px;">*</sup>, **Rui Huang**, Haoquan Zhang, Manyuan Zhang, Jiaming Liu, Shanghang Zhang, Peng Gao, Hongsheng Li, Pheng-Ann Heng


[**[PDF]**](https://arxiv.org/pdf/2501.13926) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>    [**[GithubğŸŒŸ790+]**](https://github.com/ZiyuGuo99/Image-Generation-CoT) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

**TL;DR:** *Proposed **CoT-Imag**e with step-wise reasoning and novel reward models (PARM/PARM++), improving autoregressive image generation by 24% via test-time verification and preference alignment.*


</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Under Review</div><img src='images/UniVA.png' alt="D2C" style="width: 100%; height: auto; object-fit: cover; max-height: 200px;"></div></div>
<div class='paper-box-text' markdown="1">


[ğŸ”¥UniVA: Universal Video Agents towards Next-Generation Video Intelligence](https://univa-agent.github.io/)

Zhengyang Liang<sup style="font-size: 1.1em; position: relative; top: -2px;">*</sup>, Daoan Zhang<sup style="font-size: 1.1em; position: relative; top: -2px;">*</sup>, Huichi Zhou, **Rui Huang**, Bobo Li, Shengqiong Wu, Yuechen Zhang, Xiaohan Wang, Jiebo Luo, Lizi Liao, Hao Fei


[**[PDF]**](https://univa-agent.github.io/asserts/pdf/UniVA_ICLR2025_v4.pdf) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>    [**[HomePage]**](https://univa-agent.github.io/) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>


**TL;DR:** *UniVA unifies **understanding/segmentation/editing/generation** into traceable multi-step video workflows via Planâ€“Act agents, multi-level memory, and modular tools, plus UniVA-Bench.*

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Under Review</div><img src='images/COLNet.png' alt="D2C" style="width: 100%; height: auto; object-fit: cover; max-height: 200px;"></div></div>
<div class='paper-box-text' markdown="1">

**Complementary Online Learning Network for Probabilistic Load Forecasting Against Extreme Weather**

**Rui Huang**, Pengfei Zhao, Di Cao<sup>â€ </sup>, Weihao Hu, Qi Huang, Zhe Chen


**[PDF]** <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>    **[Github]** <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

**TL;DR:** *Proposed the Complementary Online Learning Network (COLNet) with a **Weather-aware gating mechanism for high precision probabilistic** and point forecasting under extreme weather.*

</div>
</div>



- [A Novel Spatiotemporal Pyramidal Graph Modeling Approach for Short-Term Residential Load Forecasting](https://ieeexplore.ieee.org/abstract/document/11036164)

  Pengfei Zhao, Weihao Hu, Di Cao<sup>â€ </sup>, **Rui Huang**, Xingtao Bai, Qi Huang, Zhe Chen

  **IEEE Transactions on Industrial Informatics** <span style="color:rgb(42, 25, 23); font-weight: bold; text-decoration: underline;">(SCI Q1, IF: 10.2)</span>



- [Causal Mechanism-Enabled Zero-Label Learning for Power Generation Forecasting of Newly-Built PV Sites](https://ieeexplore.ieee.org/abstract/document/10679087)

  Pengfei Zhao, Weihao Hu, Di Cao<sup>â€ </sup>, **Rui Huang**, Xiawei Wu, Qi Huang, Zhe Chen

  **IEEE Transactions on Sustainable Energy** <span style="color:rgb(46, 24, 21); font-weight: bold; text-decoration: underline;">(SCI Q1, IF: 7.9)</span>



# ğŸ“– Educations
- *2023.09 - 2027.06*,  ["Everest Project"](https://www.peopleapp.com/rmharticle/30022294217) Computer Top Talent Experimental Class, University of Electronic Science and Technology of China



# ğŸ† Honors
- [2025] **SenseTime Scholarshipï¼ˆå•†æ±¤å¥–å­¦é‡‘ï¼‰** *(award rate <0.1%; 30 undergrads China-wide)* 
- [2025] **National Scholarshipï¼ˆå›½å®¶å¥–å­¦é‡‘ï¼‰** *(top recipient in the college)* 
- [2024] **National Scholarshipï¼ˆå›½å®¶å¥–å­¦é‡‘ï¼‰** *(top recipient in the college)* 
- [2024] **Gratitude Scholarship for Modern Scientists ï¼ˆæ„Ÿæ©ä¸­å›½è¿‘ç°ä»£ç§‘å­¦å®¶åŠ©å­¦é‡‘ï¼‰** *(top 10 in school)* 
- [2024] **Excellence Scholarship â€” School of Computer Science, UESTC** 
- [2024] **First-Class Scholarship for Outstanding Students** 

# ğŸ… Competition Awards
- [2025] **National Gold Award â€” National College Student Career Planning Competitionï¼ˆèŒè§„èµ›å›½é‡‘ï¼‰ğŸ…** *(award rate <0.1%; first from UESTC to receive this award)* 
- [2025] **Provincial First Prize â€” China International College Studentsâ€™ Innovation Competition ï¼ˆå›½åˆ›èµ›çœä¸€ï¼‰ğŸ…** 
- [2025] **Provincial Special Prize â€” â€œChallenge Cupâ€ National College Studentsâ€™ Extracurricular Academic and Technological Works Competitionï¼ˆæŒ‘æˆ˜æ¯çœç‰¹ï¼‰ğŸ…** 
- [2024] **National Third Prize â€” Five-Minute Research Presentation (5MRP) CompetitionğŸ¥‰** 
- [2023] **Provincial First Prize â€” Huawei ICT CompetitionğŸ…ï¼ˆåä¸ºICTçœä¸€ï¼‰** *(rank 2rd in province)* 




# ğŸ’¬ Talks ï¼† Reports
- [2025.07]  [2025å•†æ±¤å¥–å­¦é‡‘å…¬å¸ƒï¼30ä½"AIæ–°æ˜Ÿ"äº®ç›¸](https://mp.weixin.qq.com/s?__biz=MzIwNTcyNzYwMA==&mid=2247517938&idx=1&sn=66103a3998e7b3755f32af5f3be6f75b&chksm=96e07ee6277e2872fd2e00976286c33afd25a3e466b2235657aa9a7f7e425bd2049666d1f09c&mpshare=1&scene=24&srcid=0718Inq5SGowPE7uvemNIILr&sharer_shareinfo=a746172ad5ef5bcbf81c2cc917ead121&sharer_shareinfo_first=a746172ad5ef5bcbf81c2cc917ead121&clicktime=1752772305&enterid=1752772305&ascene=14&devicetype=iOS18.5&version=18003d2c&nettype=WIFI&abtest_cookie=AAACAA%3D%3D&lang=zh_CN&countrycode=CN&fontScale=100&exportkey=n_ChQIAhIQqPwcIHfowKVjYOeA6C%2BHzhLfAQIE97dBBAEAAAAAAAghJgamoiYAAAAOpnltbLcz9gKNyK89dVj0cvYatumNjj57SbppV1In%2BGmhL5mBcw8dLpPMvsDQrln9KoP6Yqd5ipvH5ma9O85VWBRBdWS2XBPnJCnzIwnNWUNU%2FLQV0bePCOLpm7iqaVTSW%2FHug927DWs5Dof7AvC9CgCPSjJFZyehad4ikLg%2FKPIpvuldlclO8bVQlRa12SHXW9EOQNSAntdRDdlB%2B3G5z96%2BhAQMKZaAAOQ4jAqOFoW1RXF7l5vBUl1vhT3mhh0odgsSB9uRPS0%3D&pass_ticket=CNrTSQMfCS8c%2BMHFmEC1jRecvwJVfSjQ5iTcZBlPLU1LtfYC0lPWwK4T5Eq7Xv2K&wx_header=3) *-Interview by SenseTime*
- [2025.07]  [é»„é”ï¼šâ€œæ‰“é€ ä»¤äººè®¤å¯çš„ä¸­å›½AIäº§å“â€](https://ruihuangai.github.io/files/cv/5845817.pdf) *-Interview by Education Herald*
- [2025.04]  [ğŸ¥‡ç¥è´ºï¼å…¨å›½é‡‘å¥–+2ï¼](https://mp.weixin.qq.com/s/eoLKKNKcTUJcSMPlTtW2sA) *-Report by UESTCâ€™s official account*
- [2025.04]  [ã€ç†æƒ³Â·æ‹…å½“ å›½å¥–é£é‡‡ã€‘é»„é”](https://mp.weixin.qq.com/s/OVhtz43FR5bH8AVfJMk1zg) *-Report by UESTC Student Financial Aid*
- [2024.10]  [ã€ç›´æ’­å›æ”¾ã€‘ç”µå­ç§‘å¤§AIç¤¾æ´»åŠ¨è¿›è¡Œä¸­](https://space.bilibili.com/3494373601839146?spm_id_from=333.788.upinfo.head.click) *-Report by UESTC Student Financial Aid*
- [2024.08]  [å®è·µå°è®°ï½œã€è‡´å¹¿å¤§ï¼Œå°½ç²¾å¾®ã€‘ç›´æ’­å¸¦è´§åŠ©åŠ›ä¹¡æ‘ç»æµï¼Œæ•™è‚²æ‰¶è´«ç‚¹äº®å¸Œæœ›ä¹‹ç¯](https://mp.weixin.qq.com/s/x_NFfYF_0fYwwFT2cZkhKg) *-Report by UESTC Social Practice*



# ğŸ“ Services
- Reviewer for **AAAI 2026**
- Co-Founder of the **UESTC AI Club**
- Deputy captain for the **â€œEmbrace the Great, Pursue the Subtleâ€ Social Practice Teamï¼ˆâ€œè‡´å¹¿å¤§ å°½ç²¾å¾®â€å®è·µé˜Ÿï¼‰**
